{
 "metadata": {
  "name": "",
  "signature": "sha256:a1931e0d0bd3def840489b22063ad484629b04948560d311a25ea2740d2eaed2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Basic IO"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Mumodo Demo Notebook ** -- Update on 24.04.2015\n",
      "\n",
      "** Summary: ** This notebook describes the basic IO functions to import data from various file types\n",
      "\n",
      "**(c) Dialogue Systems Group, University of Bielefeld**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from mumodo.mumodoIO import open_intervalframe_from_increco, open_intervalframe_from_textgrid, \\\n",
      "                            open_streamframe_from_xiofile, save_intervalframe_to_textgrid, \\\n",
      "                            save_streamframe_to_xiofile, quantize, open_intervalframe_from_increco\n",
      "from mumodo.xiofile import XIOFile\n",
      "from mumodo.increco import IncReco\n",
      "from mumodo.InstantIO import MFVec2f\n",
      "import pickle\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "IntervalFrames from Praat TextGrids"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The high level functions allow importing Interval and Stream Frames from files, e.g."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "transcriptions = open_intervalframe_from_textgrid(\"sampledata/test.TextGrid\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The function we just run returns a Python *dictionary* with the names of the tiers as keys and the IntervalFrames as values. One of these appears to be a PointFrame"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "transcriptions.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "[u'CLAPS', u'S', u'O']"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "transcriptions['S']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>start_time</th>\n",
        "      <th>end_time</th>\n",
        "      <th>text</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td>  1.30</td>\n",
        "      <td>  1.860000</td>\n",
        "      <td>                                             Hello</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td>  2.88</td>\n",
        "      <td>  3.500000</td>\n",
        "      <td>                                       I 'm Spyros</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td>  4.86</td>\n",
        "      <td>  8.280000</td>\n",
        "      <td> Here in the Dialogue Systems Group, in the Uni...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td>  8.50</td>\n",
        "      <td> 10.400000</td>\n",
        "      <td>              We have developed Mumodo, and Venice</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td> 11.58</td>\n",
        "      <td> 11.840000</td>\n",
        "      <td>                                            &lt;CLAP&gt;</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td> 14.10</td>\n",
        "      <td> 17.220000</td>\n",
        "      <td> Well, right now we are being recorded by a cam...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td> 17.54</td>\n",
        "      <td> 18.840314</td>\n",
        "      <td>                     and a Microsoft Kinect sensor</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td> 19.30</td>\n",
        "      <td> 21.100000</td>\n",
        "      <td>         But how will we get the data from Kinect?</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td> 27.70</td>\n",
        "      <td> 31.480000</td>\n",
        "      <td> We are using this timecode to synchronize the ...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td> 31.62</td>\n",
        "      <td> 32.860000</td>\n",
        "      <td>                          With the audio and video</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td> 33.76</td>\n",
        "      <td> 34.000000</td>\n",
        "      <td>                                            &lt;CLAP&gt;</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td> 37.40</td>\n",
        "      <td> 41.300000</td>\n",
        "      <td> We can process the data that comes from Venice...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td> 47.60</td>\n",
        "      <td> 47.820000</td>\n",
        "      <td>                                            &lt;CLAP&gt;</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td> 48.94</td>\n",
        "      <td> 49.660000</td>\n",
        "      <td>                                           Goodbye</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "    start_time   end_time                                               text\n",
        "0         1.30   1.860000                                              Hello\n",
        "1         2.88   3.500000                                        I 'm Spyros\n",
        "2         4.86   8.280000  Here in the Dialogue Systems Group, in the Uni...\n",
        "3         8.50  10.400000               We have developed Mumodo, and Venice\n",
        "4        11.58  11.840000                                             <CLAP>\n",
        "5        14.10  17.220000  Well, right now we are being recorded by a cam...\n",
        "6        17.54  18.840314                      and a Microsoft Kinect sensor\n",
        "7        19.30  21.100000          But how will we get the data from Kinect?\n",
        "8        27.70  31.480000  We are using this timecode to synchronize the ...\n",
        "9        31.62  32.860000                           With the audio and video\n",
        "10       33.76  34.000000                                             <CLAP>\n",
        "11       37.40  41.300000  We can process the data that comes from Venice...\n",
        "12       47.60  47.820000                                             <CLAP>\n",
        "13       48.94  49.660000                                            Goodbye"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "transcriptions['CLAPS']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>time</th>\n",
        "      <th>mark</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 11.654230</td>\n",
        "      <td>  First Clap</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 33.824485</td>\n",
        "      <td> Second Clap</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 47.672685</td>\n",
        "      <td>  Third Clap</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "        time         mark\n",
        "0  11.654230   First Clap\n",
        "1  33.824485  Second Clap\n",
        "2  47.672685   Third Clap"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to save back into a textgrid, we use a similar function, packing our Interval and PointFrames in a dict. The line below will save a Praat textgrid with two copies of the 'CLAPS' tier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "save_intervalframe_to_textgrid({'the_claps': transcriptions['CLAPS'],\n",
      "                                'the_claps_copy': transcriptions['CLAPS']}, 'newtextgrid.TextGrid')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "StreamFrames from XIO Files"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "StreamFrames can be loaded from XIO files (see below). It is important to know the *sensorname* (second argument) as data from many sensors can be stored in a single XIO file. See below (in the XIO files section) how to find out these sensornames. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mystreamframe1 = open_streamframe_from_xiofile('sampledata/test.xio.gz', 'VeniceHubReplay/Venice/Body1')\n",
      "mystreamframe2 = open_streamframe_from_xiofile('sampledata/test.xio.gz', 'VeniceHubReplay/Kinect/Face')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "opening compressed file ...\n",
        "opening file without indexing\n",
        "opening compressed file ..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "opening file without indexing\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mystreamframe1[:1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>JointPositions1</th>\n",
        "      <th>JointPositions2</th>\n",
        "      <th>JointPositions3</th>\n",
        "      <th>JointPositions4</th>\n",
        "      <th>JointPositions5</th>\n",
        "      <th>JointPositions6</th>\n",
        "      <th>time</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> []</td>\n",
        "      <td> []</td>\n",
        "      <td> [0.957876 -0.152858 1.7562, 0.945315 0.162776 ...</td>\n",
        "      <td> [-0.345256 -0.750549 0.922279, -0.359958 -0.48...</td>\n",
        "      <td> []</td>\n",
        "      <td> []</td>\n",
        "      <td> 1429192624579</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "  JointPositions1 JointPositions2  \\\n",
        "0              []              []   \n",
        "\n",
        "                                     JointPositions3  \\\n",
        "0  [0.957876 -0.152858 1.7562, 0.945315 0.162776 ...   \n",
        "\n",
        "                                     JointPositions4 JointPositions5  \\\n",
        "0  [-0.345256 -0.750549 0.922279, -0.359958 -0.48...              []   \n",
        "\n",
        "  JointPositions6           time  \n",
        "0              []  1429192624579  "
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mystreamframe2[-1:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>FaceBoxBottomRight</th>\n",
        "      <th>FaceBoxTopLeft</th>\n",
        "      <th>FaceEyeLeft</th>\n",
        "      <th>FaceEyeRight</th>\n",
        "      <th>FaceMouthLeftCorner</th>\n",
        "      <th>FaceMouthRightCorner</th>\n",
        "      <th>FaceNose</th>\n",
        "      <th>FaceProperties</th>\n",
        "      <th>FaceRotation</th>\n",
        "      <th>time</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>67160</th>\n",
        "      <td> [0.0 0.0, 0.0 0.0]</td>\n",
        "      <td> [0.0 0.0, 0.0 0.0]</td>\n",
        "      <td> [0.0 0.0, 0.0 0.0]</td>\n",
        "      <td> [0.0 0.0, 0.0 0.0]</td>\n",
        "      <td> [0.0 0.0, 0.0 0.0]</td>\n",
        "      <td> [0.0 0.0, 0.0 0.0]</td>\n",
        "      <td> [0.0 0.0, 0.0 0.0]</td>\n",
        "      <td> [11111111, 11111111]</td>\n",
        "      <td> [0.0 0.0 0.0 0.0, 0.0 0.0 0.0 0.0]</td>\n",
        "      <td> 1429192691739</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "       FaceBoxBottomRight      FaceBoxTopLeft         FaceEyeLeft  \\\n",
        "67160  [0.0 0.0, 0.0 0.0]  [0.0 0.0, 0.0 0.0]  [0.0 0.0, 0.0 0.0]   \n",
        "\n",
        "             FaceEyeRight FaceMouthLeftCorner FaceMouthRightCorner  \\\n",
        "67160  [0.0 0.0, 0.0 0.0]  [0.0 0.0, 0.0 0.0]   [0.0 0.0, 0.0 0.0]   \n",
        "\n",
        "                 FaceNose        FaceProperties  \\\n",
        "67160  [0.0 0.0, 0.0 0.0]  [11111111, 11111111]   \n",
        "\n",
        "                             FaceRotation           time  \n",
        "67160  [0.0 0.0 0.0 0.0, 0.0 0.0 0.0 0.0]  1429192691739  "
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "StreamFrames can be saved *back* to XIO files as follows. Note that we use exactly the same sensornames, although this is optional.\n",
      "\n",
      "**NOTE: ** The resulting XIO file will NOT be the same as the input file, due to *quantization*, see below"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Running the line below creates a new 1.5 MB file and takes about 20 seconds\n",
      "save_streamframe_to_xiofile({'VeniceHubReplay/Kinect/Face': mystreamframe2,\n",
      "                             'VeniceHubReplay/Venice/Body1': mystreamframe1},\n",
      "                            'newxiofile.xio.gz')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Other Options to saving Interval and Stream Frames"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Instead of saving a StreamFrame to an XIO file or an IntervalFrame to a TextGrid, there are also the following options:\n",
      "\n",
      "* Save/Load the Stream or Interval Frame as a CSV (thank you pandas!)\n",
      "* Save/Load the Stream or Interval Frame using pickle\n",
      "\n",
      "Both of these methods are faster than saving/loading to XIO files, so they are particularly helpful for StreamFrames\n",
      "\n",
      "When saving/loading from CSV, *all* objects (except maybe primitives such as floats) are turned into strings , that is, you have to parse the data into objects yourself. This is not so much of a problem for IntervalFrames, which can be safely saved into CSV files."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mystreamframe2.to_csv( \"streamframeas.csv\" )\n",
      "streamframefromcsv = pd.DataFrame.from_csv(\"streamframeas.csv\")\n",
      "assert (mystreamframe2['time'] == streamframefromcsv['time']).all()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#the StreamFrame loaded from disk has type of str for this cell\n",
      "type(mystreamframe2['FaceEyeLeft'].ix[66199]), type(streamframefromcsv['FaceEyeLeft'].ix[66199])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "(mumodo.InstantIO.MFVec2f, str)"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#reconstruct the objects in the column\n",
      "streamframefromcsv['FaceEyeLeft'] = streamframefromcsv['FaceEyeLeft'].map(lambda x: MFVec2f(x))\n",
      "#check again\n",
      "type(mystreamframe2['FaceEyeLeft'].ix[66199]), type(streamframefromcsv['FaceEyeLeft'].ix[66199])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "(mumodo.InstantIO.MFVec2f, mumodo.InstantIO.MFVec2f)"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When saving/loading using the pickle module, the objects are preserved"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pickle.dump(mystreamframe2, open( \"pickledstreamframe\", \"wb\" ) )\n",
      "unpickledstreamframe = pickle.load( open( \"pickledstreamframe\", \"rb\" ) )\n",
      "assert (mystreamframe2['time'] == unpickledstreamframe['time']).all()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(mystreamframe2['FaceEyeLeft'].ix[66199]), type(streamframefromcsv['FaceEyeLeft'].ix[66199])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "(mumodo.InstantIO.MFVec2f, mumodo.InstantIO.MFVec2f)"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However, pickle/unpickle needs you to have the object defined identically in the two Python sessions that you save/load. See the pickle module documentation for details"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "XIOFiles"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**NOTE:** The XIO format is inherited into mumodo from the *FAME* software developed by the AI group, university of Bielefeld and is also used by the *venice.hub* software, developed by the Dialogue Systems Group. Although the venice.hub format is simpler and newer, mumodo is fully backwards compatible with the original XIO format.\n",
      "\n",
      "**NOTE:** Most of the time you will not have to deal with XIO files directly, but it is good to know a little bit about their structure\n",
      "\n",
      "XIO files are XML files that contain *typed, timed events (TTE)*. The XIOFile class handles such files, e.g. to read an existing XIO file:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = XIOFile(\"sampledata/test.xio.gz\", 'r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "opening compressed file ...\n",
        "opening file without indexing\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's have a look at a few of the raw lines in the file. Note that 0, 1 are *times in milliseconds* relative to the start of the file. Because it is very verbose and consumes a lot of disk space, it is typically compressed by means of the **gzip** module, hence the gz extension. Mumodo can handle both compressed and uncompressed files. This is what the data in the file looks like"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for line in f.xio_quicklinegen(0, 1, parsed=False):\n",
      "    print line"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<mfvec3f value=\"[-0.345256 -0.750549 0.922279, -0.359958 -0.484651 0.837801, -0.365955 -0.2177 0.739759, -0.429324 -0.0832201 0.740274, -0.458221 -0.201857 0.742501, -0.533512 -0.444521 0.793084, -0.390071 -0.300809 0.549919, -0.398528 -0.205008 0.63399, -0.279814 -0.299241 0.805644, -0.40141 -0.149542 0.542428, -0.437572 0.0808716 0.556279, -0.451535 0.156582 0.563531, -0.437481 -0.722323 0.931979, -0.391703 -1.02876 0.989874, -0.426539 -0.604366 0.782481, -0.321543 -0.567326 0.807825, -0.23228 -0.736532 0.860271, -0.110944 -0.445889 1.03068, -0.362375 -0.460863 0.802363, -0.382999 -0.562574 0.700017, -0.366035 -0.2841 0.766712, -0.412893 -0.154321 0.615675, -0.409121 -0.178938 0.586998, -0.45652 0.190995 0.533486, -0.437145 0.152636 0.547568]\" timestamp=\"1429192624579\" sensorName=\"VeniceHubReplay/Venice/Body1/JointPositions4\"/>\n",
        "\n",
        "<mfvec3f value=\"[]\" timestamp=\"1429192624580\" sensorName=\"VeniceHubReplay/Venice/Body1/JointPositions6\"/>\n",
        "\n",
        "<mfvec3f value=\"[]\" timestamp=\"1429192624580\" sensorName=\"VeniceHubReplay/Venice/Body1/JointPositions5\"/>\n",
        "\n",
        "<mfvec2f value=\"[0.0 0.0, 0.0 0.0]\" timestamp=\"1429192624580\" sensorName=\"VeniceHubReplay/Kinect/Face/FaceEyeRight\"/>\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Each of these lines represents a typed, timed event (TTE). That is, each *event* has a timestamp, a type, a value and a sensorname/fieldname combo. The latter part is parsed as follows. The last part of the sensorname attribute (anything after the last \"/\" becomes the fieldname (and eventually a column in an imported stream frame) while the rest is the sensorname itself. Here are the same lines as above, but now they are parsed. We see that already the strings have been parsed into basic InstantIO objects (see Basic Types demo notebook)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for line in f.xio_quicklinegen(0, 1):\n",
      "    print line"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'valuetype': 'mfvec3f', 'fieldname': 'JointPositions4', 'sensorname': 'VeniceHubReplay/Venice/Body1', 'value': <mumodo.InstantIO.MFVec3f object at 0x114914d10>, 'time': 1429192624579}\n",
        "{'valuetype': 'mfvec3f', 'fieldname': 'JointPositions6', 'sensorname': 'VeniceHubReplay/Venice/Body1', 'value': <mumodo.InstantIO.MFVec3f object at 0x114914d90>, 'time': 1429192624580}\n",
        "{'valuetype': 'mfvec3f', 'fieldname': 'JointPositions5', 'sensorname': 'VeniceHubReplay/Venice/Body1', 'value': <mumodo.InstantIO.MFVec3f object at 0x10eff0990>, 'time': 1429192624580}\n",
        "{'valuetype': 'mfvec2f', 'fieldname': 'FaceEyeRight', 'sensorname': 'VeniceHubReplay/Kinect/Face', 'value': <mumodo.InstantIO.MFVec2f object at 0x10eff08d0>, 'time': 1429192624580}\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Useful XIO commands"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Two typical actions that you may need to do on XIO files are:\n",
      "\n",
      "* finding out the *minimum timestamp* of an XIO file\n",
      "* finding out all possible sensornames that can be imported as streamframes\n",
      "\n",
      "The first is very easy, here is an one-liner:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "XIOFile(\"sampledata/test.xio.gz\", \"r\").min_time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "opening compressed file ...\n",
        "opening file without indexing\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "1429192624579"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The second one, little bit trickier, requires opening the XIO file in *indexed* mode, which is a debug mode that pre-parses the entire file. In order to limit this, we only parse a part of the file (1000 lines), if we know that data from all the sensors we want has been logged in this first part:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "XIOFile(\"sampledata/test.xio.gz\", indexing=True, maxlines=1000).fieldnames.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "opening compressed file ...\n",
        "indexing ...\n",
        "unable to parse line  2   <venice>\n",
        "\n",
        "done! (indexed 1000 lines)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "['', 'VeniceHubReplay/Venice/Body1', 'VeniceHubReplay/Kinect/Face']"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Quantization"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When importing a StreamFrame from an XIOFile, you convert this sequential, asynchronous event stream into a *table*. It is quite common that data from the same sensor is logged asybchronously, with slightly different timestamps (this is in part due to the way the venice.hub and other loggers work). For example, data from the same sensor could arrive at the following timestamps (which have been made relative to min_time for convenience)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "timestamps = []\n",
      "for line in f.xio_quicklinegen(5000, 5300):\n",
      "    if 'Body' in line['sensorname']:\n",
      "        timestamps.append(line['time'] - f.min_time)\n",
      "print timestamps"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[5015, 5016, 5016, 5016, 5016, 5016, 5050, 5050, 5050, 5050, 5050, 5050, 5082, 5083, 5083, 5083, 5083, 5083, 5115, 5116, 5116, 5116, 5116, 5116, 5149, 5150, 5150, 5150, 5150, 5150, 5182, 5183, 5183, 5183, 5183, 5183, 5215, 5216, 5216, 5217, 5217, 5217, 5249, 5249, 5249, 5249, 5249, 5249, 5281, 5282, 5282, 5282, 5282, 5282]\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "we notice that the sensor outputs 6 values roughly every ~33 ms, which corresponds to 30 frames per second (fps). If we allowed each timestamp to become a row in a StreamFrame, we would have many empty cells. In order to avoid this, we *quantize* the data as follows: \n",
      "\n",
      "When a new event is parsed (e.g. at time 5015) a *window* is opened for 5 ms (configurable) and all events received thereafter are added to the same frame. This is the job of the *quantize()* function. \n",
      "\n",
      "See how the objects at the timestamps above are packed into dictionaries below. Each dictionary is a \"frame\". The original timestamp is shown for each frame. It corresponds to the time of the *first* event in the XIO file that was added to this frame, i.e. the start of the window. But, in reality, some of the field values might have been logged up to 5 ms later.\n",
      "\n",
      "As a result, the timestamps of the individual events are \"quantized\" into the times of the *frames*. When writing this data back to an XIO file, the events will have these new timestamps instead of their original ones."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "list(quantize(f.xio_quicklinegen(5000, 5300), 'VeniceHubReplay/Venice/Body1'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "[{'JointPositions1': <mumodo.InstantIO.MFVec3f at 0x11094a890>,\n",
        "  'JointPositions2': <mumodo.InstantIO.MFVec3f at 0x114914f90>,\n",
        "  'JointPositions3': <mumodo.InstantIO.MFVec3f at 0x10eff0990>,\n",
        "  'JointPositions4': <mumodo.InstantIO.MFVec3f at 0x11094a5d0>,\n",
        "  'JointPositions5': <mumodo.InstantIO.MFVec3f at 0x11094a6d0>,\n",
        "  'JointPositions6': <mumodo.InstantIO.MFVec3f at 0x11094a650>,\n",
        "  'time': 1429192629594},\n",
        " {'JointPositions1': <mumodo.InstantIO.MFVec3f at 0x114914b10>,\n",
        "  'JointPositions2': <mumodo.InstantIO.MFVec3f at 0x114914c90>,\n",
        "  'JointPositions3': <mumodo.InstantIO.MFVec3f at 0x11094a550>,\n",
        "  'JointPositions4': <mumodo.InstantIO.MFVec3f at 0x114914d50>,\n",
        "  'JointPositions5': <mumodo.InstantIO.MFVec3f at 0x114914a10>,\n",
        "  'JointPositions6': <mumodo.InstantIO.MFVec3f at 0x114914cd0>,\n",
        "  'time': 1429192629629},\n",
        " {'JointPositions1': <mumodo.InstantIO.MFVec3f at 0x10eff0850>,\n",
        "  'JointPositions2': <mumodo.InstantIO.MFVec3f at 0x10eff0a90>,\n",
        "  'JointPositions3': <mumodo.InstantIO.MFVec3f at 0x114914ad0>,\n",
        "  'JointPositions4': <mumodo.InstantIO.MFVec3f at 0x10eff0a10>,\n",
        "  'JointPositions5': <mumodo.InstantIO.MFVec3f at 0x10eff09d0>,\n",
        "  'JointPositions6': <mumodo.InstantIO.MFVec3f at 0x10eff0750>,\n",
        "  'time': 1429192629661},\n",
        " {'JointPositions1': <mumodo.InstantIO.MFVec3f at 0x11094a850>,\n",
        "  'JointPositions2': <mumodo.InstantIO.MFVec3f at 0x11094a590>,\n",
        "  'JointPositions3': <mumodo.InstantIO.MFVec3f at 0x110d84490>,\n",
        "  'JointPositions4': <mumodo.InstantIO.MFVec3f at 0x11094a710>,\n",
        "  'JointPositions5': <mumodo.InstantIO.MFVec3f at 0x11094a610>,\n",
        "  'JointPositions6': <mumodo.InstantIO.MFVec3f at 0x11094a790>,\n",
        "  'time': 1429192629694},\n",
        " {'JointPositions1': <mumodo.InstantIO.MFVec3f at 0x110d78d90>,\n",
        "  'JointPositions2': <mumodo.InstantIO.MFVec3f at 0x110d78cd0>,\n",
        "  'JointPositions3': <mumodo.InstantIO.MFVec3f at 0x114914fd0>,\n",
        "  'JointPositions4': <mumodo.InstantIO.MFVec3f at 0x110d78d50>,\n",
        "  'JointPositions5': <mumodo.InstantIO.MFVec3f at 0x110d78790>,\n",
        "  'JointPositions6': <mumodo.InstantIO.MFVec3f at 0x110d788d0>,\n",
        "  'time': 1429192629728},\n",
        " {'JointPositions1': <mumodo.InstantIO.MFVec3f at 0x1110aa310>,\n",
        "  'JointPositions2': <mumodo.InstantIO.MFVec3f at 0x1110aa2d0>,\n",
        "  'JointPositions3': <mumodo.InstantIO.MFVec3f at 0x110d78d10>,\n",
        "  'JointPositions4': <mumodo.InstantIO.MFVec3f at 0x11094a8d0>,\n",
        "  'JointPositions5': <mumodo.InstantIO.MFVec3f at 0x11094a690>,\n",
        "  'JointPositions6': <mumodo.InstantIO.MFVec3f at 0x1110aa990>,\n",
        "  'time': 1429192629761},\n",
        " {'JointPositions1': <mumodo.InstantIO.MFVec3f at 0x1110ab890>,\n",
        "  'JointPositions2': <mumodo.InstantIO.MFVec3f at 0x1110ab110>,\n",
        "  'JointPositions3': <mumodo.InstantIO.MFVec3f at 0x114914f10>,\n",
        "  'JointPositions4': <mumodo.InstantIO.MFVec3f at 0x1110abf50>,\n",
        "  'JointPositions5': <mumodo.InstantIO.MFVec3f at 0x1110ab850>,\n",
        "  'JointPositions6': <mumodo.InstantIO.MFVec3f at 0x1110ab050>,\n",
        "  'time': 1429192629794},\n",
        " {'JointPositions1': <mumodo.InstantIO.MFVec3f at 0x110d84450>,\n",
        "  'JointPositions2': <mumodo.InstantIO.MFVec3f at 0x110d84b50>,\n",
        "  'JointPositions3': <mumodo.InstantIO.MFVec3f at 0x110d84bd0>,\n",
        "  'JointPositions4': <mumodo.InstantIO.MFVec3f at 0x110d84b90>,\n",
        "  'JointPositions5': <mumodo.InstantIO.MFVec3f at 0x110d84c10>,\n",
        "  'JointPositions6': <mumodo.InstantIO.MFVec3f at 0x110d844d0>,\n",
        "  'time': 1429192629828},\n",
        " {'JointPositions1': <mumodo.InstantIO.MFVec3f at 0x1110ab0d0>,\n",
        "  'JointPositions2': <mumodo.InstantIO.MFVec3f at 0x110d78b10>,\n",
        "  'JointPositions3': <mumodo.InstantIO.MFVec3f at 0x10f9d8b90>,\n",
        "  'JointPositions4': <mumodo.InstantIO.MFVec3f at 0x1110ab7d0>,\n",
        "  'JointPositions5': <mumodo.InstantIO.MFVec3f at 0x1110ab090>,\n",
        "  'JointPositions6': <mumodo.InstantIO.MFVec3f at 0x1110ab810>,\n",
        "  'time': 1429192629860}]"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Inc_Reco files"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "inc_recos are special files that are useful within the Incremental Unit (IU) framework.\n",
      "\n",
      "They store information about units at different update times. Automatic Speech Recognition (ASR) results that are output incrementally can be stored in these files. Each update time is accompanied by a \"chunk\" of the output (the output at that time).\n",
      "\n",
      "Here is what they look like:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('sampledata/test.inc_reco') as f:\n",
      "    lines = 0\n",
      "    while lines < 22:\n",
      "        print f.readline()[:-1]\n",
      "        lines += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 3.97\n",
        "3.925\t3.941\toh\n",
        "3.941\t3.958\tyou\n",
        "3.958\t3.974\tmean\n",
        "\n",
        "Time: 4.17\n",
        "3.925\t3.941\toh\n",
        "3.941\t3.958\tyou\n",
        "3.958\t3.974\tmean\n",
        "4.123\t4.173\tthe\n",
        "\n",
        "Time: 4.30\n",
        "3.925\t3.941\toh\n",
        "3.941\t3.958\tyou\n",
        "3.958\t3.974\tmean\n",
        "\n",
        "Time: 5.16\n",
        "3.925\t3.941\toh\n",
        "3.941\t3.958\tyou\n",
        "3.958\t3.974\tmean\n",
        "5.009\t5.165\tthe\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "But the IncReco class handles these files nicely, e.g."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myincreco = IncReco(\"sampledata/test.inc_reco\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get all the update times\n",
      "print myincreco.get_times()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[3.97, 4.17, 4.3, 5.16, 5.21, 5.7, 7.53, 8.95, 9.34, 9.39, 9.4, 9.44, 9.52, 9.97]\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get the latest chunk at a specific time\n",
      "myincreco.get_latest_chunk(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "{'Chunk': [['3.925', '3.941', 'oh'],\n",
        "  ['3.941', '3.958', 'you'],\n",
        "  ['3.958', '3.974', 'mean']],\n",
        " 'Time': 4.3}"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get the very last chunk -> final output\n",
      "myincreco.get_last_chunk()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "{'Chunk': [['3.925', '3.941', 'oh'],\n",
        "  ['3.941', '3.958', 'you'],\n",
        "  ['3.958', '3.974', 'mean'],\n",
        "  ['5.009', '5.165', 'the'],\n",
        "  ['5.211', '5.215', 'learning'],\n",
        "  ['5.615', '5.695', 'type'],\n",
        "  ['7.285', '7.366', 'i'],\n",
        "  ['7.366', '7.446', 'mean'],\n",
        "  ['7.446', '7.527', 'actual'],\n",
        "  ['8.939', '8.940', 'experiment'],\n",
        "  ['9.327', '9.332', 'that'],\n",
        "  ['9.332', '9.337', 'would'],\n",
        "  ['9.378', '9.381', 'have'],\n",
        "  ['9.395', '9.395', 'to'],\n",
        "  ['9.430', '9.431', 'get'],\n",
        "  ['9.505', '9.510', 'your'],\n",
        "  ['9.953', '9.961', 'permission']],\n",
        " 'Time': 9.97}"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In addition, you can import an IncReco such as the above as a dictionary of IntervalFrames (one for each chunk):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myrecodict = open_intervalframe_from_increco('sampledata/test.inc_reco')\n",
      "print myrecodict.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['9.44', '7.53', '9.34', '4.17', '4.3', '5.7', '9.39', '3.97', '8.95', '9.52', '5.16', '5.21', '9.4', '9.97']\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#display the final output intervalframe\n",
      "myrecodict['9.97']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>start_time</th>\n",
        "      <th>end_time</th>\n",
        "      <th>text</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td> 3.925</td>\n",
        "      <td> 3.941</td>\n",
        "      <td>         oh</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td> 3.941</td>\n",
        "      <td> 3.958</td>\n",
        "      <td>        you</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td> 3.958</td>\n",
        "      <td> 3.974</td>\n",
        "      <td>       mean</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td> 5.009</td>\n",
        "      <td> 5.165</td>\n",
        "      <td>        the</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td> 5.211</td>\n",
        "      <td> 5.215</td>\n",
        "      <td>   learning</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td> 5.615</td>\n",
        "      <td> 5.695</td>\n",
        "      <td>       type</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td> 7.285</td>\n",
        "      <td> 7.366</td>\n",
        "      <td>          i</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td> 7.366</td>\n",
        "      <td> 7.446</td>\n",
        "      <td>       mean</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td> 7.446</td>\n",
        "      <td> 7.527</td>\n",
        "      <td>     actual</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td> 8.939</td>\n",
        "      <td> 8.940</td>\n",
        "      <td> experiment</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td> 9.327</td>\n",
        "      <td> 9.332</td>\n",
        "      <td>       that</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td> 9.332</td>\n",
        "      <td> 9.337</td>\n",
        "      <td>      would</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td> 9.378</td>\n",
        "      <td> 9.381</td>\n",
        "      <td>       have</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td> 9.395</td>\n",
        "      <td> 9.395</td>\n",
        "      <td>         to</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td> 9.430</td>\n",
        "      <td> 9.431</td>\n",
        "      <td>        get</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15</th>\n",
        "      <td> 9.505</td>\n",
        "      <td> 9.510</td>\n",
        "      <td>       your</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td> 9.953</td>\n",
        "      <td> 9.961</td>\n",
        "      <td> permission</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "    start_time  end_time        text\n",
        "0        3.925     3.941          oh\n",
        "1        3.941     3.958         you\n",
        "2        3.958     3.974        mean\n",
        "3        5.009     5.165         the\n",
        "4        5.211     5.215    learning\n",
        "5        5.615     5.695        type\n",
        "6        7.285     7.366           i\n",
        "7        7.366     7.446        mean\n",
        "8        7.446     7.527      actual\n",
        "9        8.939     8.940  experiment\n",
        "10       9.327     9.332        that\n",
        "11       9.332     9.337       would\n",
        "12       9.378     9.381        have\n",
        "13       9.395     9.395          to\n",
        "14       9.430     9.431         get\n",
        "15       9.505     9.510        your\n",
        "16       9.953     9.961  permission"
       ]
      }
     ],
     "prompt_number": 29
    }
   ],
   "metadata": {}
  }
 ]
}
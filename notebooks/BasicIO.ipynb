{
 "metadata": {
  "name": "",
  "signature": "sha256:79bf47dafd6ef06316cf4033ef5f3968006312a4f751feef9a5b1a4e880a8050"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Basic IO"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Mumodo Demo Notebook ** -- Update on 24.04.2015\n",
      "\n",
      "** Summary: ** This notebook describes the basic IO functions to import data from various file types\n",
      "\n",
      "**(c) Dialogue Systems Group, University of Bielefeld**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from mumodo.mumodoIO import open_intervalframe_from_increco, open_intervalframe_from_textgrid, \\\n",
      "                            open_streamframe_from_xiofile, save_intervalframe_to_textgrid, \\\n",
      "                            save_streamframe_to_xiofile, quantize, open_intervalframe_from_increco\n",
      "from mumodo.xiofile import XIOFile\n",
      "from mumodo.increco import IncReco\n",
      "from mumodo.InstantIO import MFVec2f\n",
      "import pickle\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "IntervalFrames from Praat TextGrids"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The high level functions allow importing Interval and Stream Frames from files, e.g."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "transcriptions = open_intervalframe_from_textgrid(\"sampledata/test.TextGrid\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The function we just run returns a Python *dictionary* with the names of the tiers as keys and the IntervalFrames as values. One of these appears to be a PointFrame"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "transcriptions.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "[u'CLAPS', u'S', u'O']"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "transcriptions['S']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>start_time</th>\n",
        "      <th>end_time</th>\n",
        "      <th>text</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td>  1.30</td>\n",
        "      <td>  1.860000</td>\n",
        "      <td>                                             Hello</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td>  2.88</td>\n",
        "      <td>  3.500000</td>\n",
        "      <td>                                       I 'm Spyros</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td>  4.86</td>\n",
        "      <td>  8.280000</td>\n",
        "      <td> Here in the Dialogue Systems Group, in the Uni...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td>  8.50</td>\n",
        "      <td> 10.400000</td>\n",
        "      <td>              We have developed Mumodo, and Venice</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td> 11.58</td>\n",
        "      <td> 11.840000</td>\n",
        "      <td>                                            &lt;CLAP&gt;</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td> 14.10</td>\n",
        "      <td> 17.220000</td>\n",
        "      <td> Well, right now we are being recorded by a cam...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td> 17.54</td>\n",
        "      <td> 18.840314</td>\n",
        "      <td>                     and a Microsoft Kinect sensor</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td> 19.30</td>\n",
        "      <td> 21.100000</td>\n",
        "      <td>         But how will we get the data from Kinect?</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td> 27.70</td>\n",
        "      <td> 31.480000</td>\n",
        "      <td> We are using this timecode to synchronize the ...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td> 31.62</td>\n",
        "      <td> 32.860000</td>\n",
        "      <td>                          With the audio and video</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td> 33.76</td>\n",
        "      <td> 34.000000</td>\n",
        "      <td>                                            &lt;CLAP&gt;</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td> 37.40</td>\n",
        "      <td> 41.300000</td>\n",
        "      <td> We can process the data that comes from Venice...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td> 47.60</td>\n",
        "      <td> 47.820000</td>\n",
        "      <td>                                            &lt;CLAP&gt;</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td> 48.94</td>\n",
        "      <td> 49.660000</td>\n",
        "      <td>                                           Goodbye</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "    start_time   end_time                                               text\n",
        "0         1.30   1.860000                                              Hello\n",
        "1         2.88   3.500000                                        I 'm Spyros\n",
        "2         4.86   8.280000  Here in the Dialogue Systems Group, in the Uni...\n",
        "3         8.50  10.400000               We have developed Mumodo, and Venice\n",
        "4        11.58  11.840000                                             <CLAP>\n",
        "5        14.10  17.220000  Well, right now we are being recorded by a cam...\n",
        "6        17.54  18.840314                      and a Microsoft Kinect sensor\n",
        "7        19.30  21.100000          But how will we get the data from Kinect?\n",
        "8        27.70  31.480000  We are using this timecode to synchronize the ...\n",
        "9        31.62  32.860000                           With the audio and video\n",
        "10       33.76  34.000000                                             <CLAP>\n",
        "11       37.40  41.300000  We can process the data that comes from Venice...\n",
        "12       47.60  47.820000                                             <CLAP>\n",
        "13       48.94  49.660000                                            Goodbye"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "transcriptions['CLAPS']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>time</th>\n",
        "      <th>mark</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 11.654230</td>\n",
        "      <td>  First Clap</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 33.824485</td>\n",
        "      <td> Second Clap</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 47.672685</td>\n",
        "      <td>  Third Clap</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "        time         mark\n",
        "0  11.654230   First Clap\n",
        "1  33.824485  Second Clap\n",
        "2  47.672685   Third Clap"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to save back into a textgrid, we use a similar function, packing our Interval and PointFrames in a dict. The line below will save a Praat textgrid with two copies of the 'CLAPS' tier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "save_intervalframe_to_textgrid({'the_claps': transcriptions['CLAPS'],\n",
      "                                'the_claps_copy': transcriptions['CLAPS']}, 'newtextgrid.TextGrid')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "StreamFrames from XIO Files"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "StreamFrames can be loaded from XIO files (see below). It is important to know the *sensorname* (second argument) as data from many sensors can be stored in a single XIO file. See below (in the XIO files section) how to find out these sensornames. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mystreamframe1 = open_streamframe_from_xiofile('sampledata/test.xio.gz', 'VeniceHubReplay/Venice/Body1')\n",
      "mystreamframe2 = open_streamframe_from_xiofile('sampledata/test.xio.gz', 'VeniceHubReplay/Kinect/Face')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "opening compressed file ...\n",
        "opening file without indexing\n",
        "opening compressed file ..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "opening file without indexing\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mystreamframe1[:1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>JointPositions1</th>\n",
        "      <th>JointPositions2</th>\n",
        "      <th>JointPositions3</th>\n",
        "      <th>JointPositions4</th>\n",
        "      <th>JointPositions5</th>\n",
        "      <th>JointPositions6</th>\n",
        "      <th>time</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> []</td>\n",
        "      <td> []</td>\n",
        "      <td> [0.957876 -0.152858 1.7562, 0.945315 0.162776 ...</td>\n",
        "      <td> [-0.345256 -0.750549 0.922279, -0.359958 -0.48...</td>\n",
        "      <td> []</td>\n",
        "      <td> []</td>\n",
        "      <td> 1429192624579</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "  JointPositions1 JointPositions2  \\\n",
        "0              []              []   \n",
        "\n",
        "                                     JointPositions3  \\\n",
        "0  [0.957876 -0.152858 1.7562, 0.945315 0.162776 ...   \n",
        "\n",
        "                                     JointPositions4 JointPositions5  \\\n",
        "0  [-0.345256 -0.750549 0.922279, -0.359958 -0.48...              []   \n",
        "\n",
        "  JointPositions6           time  \n",
        "0              []  1429192624579  "
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mystreamframe2[-1:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>FaceBoxBottomRight</th>\n",
        "      <th>FaceBoxTopLeft</th>\n",
        "      <th>FaceEyeLeft</th>\n",
        "      <th>FaceEyeRight</th>\n",
        "      <th>FaceMouthLeftCorner</th>\n",
        "      <th>FaceMouthRightCorner</th>\n",
        "      <th>FaceNose</th>\n",
        "      <th>FaceProperties</th>\n",
        "      <th>FaceRotation</th>\n",
        "      <th>time</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>67160</th>\n",
        "      <td> [0.0 0.0, 0.0 0.0]</td>\n",
        "      <td> [0.0 0.0, 0.0 0.0]</td>\n",
        "      <td> [0.0 0.0, 0.0 0.0]</td>\n",
        "      <td> [0.0 0.0, 0.0 0.0]</td>\n",
        "      <td> [0.0 0.0, 0.0 0.0]</td>\n",
        "      <td> [0.0 0.0, 0.0 0.0]</td>\n",
        "      <td> [0.0 0.0, 0.0 0.0]</td>\n",
        "      <td> [11111111, 11111111]</td>\n",
        "      <td> [0.0 0.0 0.0 0.0, 0.0 0.0 0.0 0.0]</td>\n",
        "      <td> 1429192691739</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "       FaceBoxBottomRight      FaceBoxTopLeft         FaceEyeLeft  \\\n",
        "67160  [0.0 0.0, 0.0 0.0]  [0.0 0.0, 0.0 0.0]  [0.0 0.0, 0.0 0.0]   \n",
        "\n",
        "             FaceEyeRight FaceMouthLeftCorner FaceMouthRightCorner  \\\n",
        "67160  [0.0 0.0, 0.0 0.0]  [0.0 0.0, 0.0 0.0]   [0.0 0.0, 0.0 0.0]   \n",
        "\n",
        "                 FaceNose        FaceProperties  \\\n",
        "67160  [0.0 0.0, 0.0 0.0]  [11111111, 11111111]   \n",
        "\n",
        "                             FaceRotation           time  \n",
        "67160  [0.0 0.0 0.0 0.0, 0.0 0.0 0.0 0.0]  1429192691739  "
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "StreamFrames can be saved *back* to XIO files as follows. Note that we use exactly the same sensornames, although this is optional.\n",
      "\n",
      "**NOTE: ** The resulting XIO file will NOT be the same as the input file, due to *quantization*, see below"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Running the line below creates a new 1.5 MB file and takes about 20 seconds\n",
      "save_streamframe_to_xiofile({'VeniceHubReplay/Kinect/Face': mystreamframe2,\n",
      "                             'VeniceHubReplay/Venice/Body1': mystreamframe1},\n",
      "                            'newxiofile.xio.gz')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Other Options to saving Interval and Stream Frames"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Instead of saving a StreamFrame to an XIO file or an IntervalFrame to a TextGrid, there are also the following options:\n",
      "\n",
      "* Save/Load the Stream or Interval Frame as a CSV (thank you pandas!)\n",
      "* Save/Load the Stream or Interval Frame using pickle\n",
      "\n",
      "Both of these methods are faster than saving/loading to XIO files, so they are particularly helpful for StreamFrames\n",
      "\n",
      "When saving/loading from CSV, *all* objects (except maybe primitives such as floats) are turned into strings , that is, you have to parse the data into objects yourself. This is not so much of a problem for IntervalFrames, which can be safely saved into CSV files."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mystreamframe2.to_csv( \"streamframeas.csv\" )\n",
      "streamframefromcsv = pd.DataFrame.from_csv(\"streamframeas.csv\")\n",
      "assert (mystreamframe2['time'] == streamframefromcsv['time']).all()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#the StreamFrame loaded from disk has type of str for this cell\n",
      "type(mystreamframe2['FaceEyeLeft'].ix[66199]), type(streamframefromcsv['FaceEyeLeft'].ix[66199])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "(mumodo.InstantIO.MFVec2f, str)"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#reconstruct the objects in the column\n",
      "streamframefromcsv['FaceEyeLeft'] = streamframefromcsv['FaceEyeLeft'].map(lambda x: MFVec2f(x))\n",
      "#check again\n",
      "type(mystreamframe2['FaceEyeLeft'].ix[66199]), type(streamframefromcsv['FaceEyeLeft'].ix[66199])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "(mumodo.InstantIO.MFVec2f, mumodo.InstantIO.MFVec2f)"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When saving/loading using the pickle module, the objects are preserved"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pickle.dump(mystreamframe2, open( \"pickledstreamframe\", \"wb\" ) )\n",
      "unpickledstreamframe = pickle.load( open( \"pickledstreamframe\", \"rb\" ) )\n",
      "assert (mystreamframe2['time'] == unpickledstreamframe['time']).all()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(mystreamframe2['FaceEyeLeft'].ix[66199]), type(streamframefromcsv['FaceEyeLeft'].ix[66199])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "(mumodo.InstantIO.MFVec2f, mumodo.InstantIO.MFVec2f)"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However, pickle/unpickle needs you to have the object defined identically in the two Python sessions that you save/load. See the pickle module documentation for details"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "XIOFiles"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**NOTE:** The XIO format is inherited into mumodo from the *FAME* software developed by the AI group, university of Bielefeld and is also used by the *venice.hub* software, developed by the Dialogue Systems Group. Although the venice.hub format is simpler and newer, mumodo is fully backwards compatible with the original XIO format.\n",
      "\n",
      "**NOTE:** Most of the time you will not have to deal with XIO files directly, but it is good to know a little bit about their structure\n",
      "\n",
      "XIO files are XML files that contain *typed, timed events (TTE)*. The XIOFile class handles such files, e.g. to read an existing XIO file:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = XIOFile(\"sampledata/test.xio.gz\", 'r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "opening compressed file ...\n",
        "opening file without indexing\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's have a look at a few of the raw lines in the file. Note that 0, 1 are *times in milliseconds* relative to the start of the file. Because it is very verbose and consumes a lot of disk space, it is typically compressed by means of the **gzip** module, hence the gz extension. Mumodo can handle both compressed and uncompressed files. This is what the data in the file looks like"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for line in f.xio_quicklinegen(0, 1, parsed=False):\n",
      "    print line"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<mfvec3f value=\"[-0.345256 -0.750549 0.922279, -0.359958 -0.484651 0.837801, -0.365955 -0.2177 0.739759, -0.429324 -0.0832201 0.740274, -0.458221 -0.201857 0.742501, -0.533512 -0.444521 0.793084, -0.390071 -0.300809 0.549919, -0.398528 -0.205008 0.63399, -0.279814 -0.299241 0.805644, -0.40141 -0.149542 0.542428, -0.437572 0.0808716 0.556279, -0.451535 0.156582 0.563531, -0.437481 -0.722323 0.931979, -0.391703 -1.02876 0.989874, -0.426539 -0.604366 0.782481, -0.321543 -0.567326 0.807825, -0.23228 -0.736532 0.860271, -0.110944 -0.445889 1.03068, -0.362375 -0.460863 0.802363, -0.382999 -0.562574 0.700017, -0.366035 -0.2841 0.766712, -0.412893 -0.154321 0.615675, -0.409121 -0.178938 0.586998, -0.45652 0.190995 0.533486, -0.437145 0.152636 0.547568]\" timestamp=\"1429192624579\" sensorName=\"VeniceHubReplay/Venice/Body1/JointPositions4\"/>\n",
        "\n",
        "<mfvec3f value=\"[]\" timestamp=\"1429192624580\" sensorName=\"VeniceHubReplay/Venice/Body1/JointPositions6\"/>\n",
        "\n",
        "<mfvec3f value=\"[]\" timestamp=\"1429192624580\" sensorName=\"VeniceHubReplay/Venice/Body1/JointPositions5\"/>\n",
        "\n",
        "<mfvec2f value=\"[0.0 0.0, 0.0 0.0]\" timestamp=\"1429192624580\" sensorName=\"VeniceHubReplay/Kinect/Face/FaceEyeRight\"/>\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Each of these lines represents a typed, timed event (TTE). That is, each *event* has a timestamp, a type, a value and a sensorname/fieldname combo. The latter part is parsed as follows. The last part of the sensorname attribute (anything after the last \"/\" becomes the fieldname (and eventually a column in an imported stream frame) while the rest is the sensorname itself. Here are the same lines as above, but now they are parsed. We see that already the strings have been parsed into basic InstantIO objects (see Basic Types demo notebook)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for line in f.xio_quicklinegen(0, 1):\n",
      "    print line"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'valuetype': 'mfvec3f', 'fieldname': 'JointPositions4', 'sensorname': 'VeniceHubReplay/Venice/Body1', 'value': <mumodo.InstantIO.MFVec3f object at 0x10f629710>, 'time': 1429192624579}\n",
        "{'valuetype': 'mfvec3f', 'fieldname': 'JointPositions6', 'sensorname': 'VeniceHubReplay/Venice/Body1', 'value': <mumodo.InstantIO.MFVec3f object at 0x11098a710>, 'time': 1429192624580}\n",
        "{'valuetype': 'mfvec3f', 'fieldname': 'JointPositions5', 'sensorname': 'VeniceHubReplay/Venice/Body1', 'value': <mumodo.InstantIO.MFVec3f object at 0x112fd5b10>, 'time': 1429192624580}\n",
        "{'valuetype': 'mfvec2f', 'fieldname': 'FaceEyeRight', 'sensorname': 'VeniceHubReplay/Kinect/Face', 'value': <mumodo.InstantIO.MFVec2f object at 0x112fd5b50>, 'time': 1429192624580}\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Useful XIO commands"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Two typical actions that you may need to do on XIO files are:\n",
      "\n",
      "* finding out the *minimum timestamp* of an XIO file\n",
      "* finding out all possible sensornames that can be imported as streamframes\n",
      "\n",
      "The first is very easy, here is an one-liner:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "XIOFile(\"sampledata/test.xio.gz\", \"r\").min_time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "opening compressed file ...\n",
        "opening file without indexing\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "1429192624579"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The second one, little bit trickier, requires opening the XIO file in *indexed* mode, which is a debug mode that pre-parses the entire file. In order to limit this, we only parse a part of the file (1000 lines), if we know that data from all the sensors we want has been logged in this first part:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "XIOFile(\"sampledata/test.xio.gz\", indexing=True, maxlines=1000).fieldnames.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "opening compressed file ...\n",
        "indexing ...\n",
        "unable to parse line  2   <venice>\n",
        "\n",
        "done! (indexed 1000 lines)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "['', 'VeniceHubReplay/Venice/Body1', 'VeniceHubReplay/Kinect/Face']"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Quantization"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When importing a StreamFrame from an XIOFile, you convert this sequential, asynchronous event stream into a *table*. It is quite common that data from the same sensor is logged asybchronously, with slightly different timestamps (this is in part due to the way the venice.hub and other loggers work). For example, data from the same sensor could arrive at the following timestamps (which have been made relative to min_time for convenience)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "timestamps = []\n",
      "for line in f.xio_quicklinegen(5000, 5300):\n",
      "    if 'Body' in line['sensorname']:\n",
      "        timestamps.append(line['time'] - f.min_time)\n",
      "print timestamps"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[5015, 5016, 5016, 5016, 5016, 5016, 5050, 5050, 5050, 5050, 5050, 5050, 5082, 5083, 5083, 5083, 5083, 5083, 5115, 5116, 5116, 5116, 5116, 5116, 5149, 5150, 5150, 5150, 5150, 5150, 5182, 5183, 5183, 5183, 5183, 5183, 5215, 5216, 5216, 5217, 5217, 5217, 5249, 5249, 5249, 5249, 5249, 5249, 5281, 5282, 5282, 5282, 5282, 5282]\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "we notice that the sensor outputs 6 values roughly every ~33 ms, which corresponds to 30 frames per second (fps). If we allowed each timestamp to become a row in a StreamFrame, we would have many empty cells. In order to avoid this, we *quantize* the data as follows: \n",
      "\n",
      "When a new event is parsed (e.g. at time 5015) a *window* is opened for 5 ms (configurable) and all events received thereafter are added to the same frame. This is the job of the *quantize()* function. \n",
      "\n",
      "See how the objects at the timestamps above are packed into dictionaries below. Each dictionary is a \"frame\". The original timestamp is shown for each frame. It corresponds to the time of the *first* event in the XIO file that was added to this frame, i.e. the start of the window. But, in reality, some of the field values might have been logged up to 5 ms later.\n",
      "\n",
      "As a result, the timestamps of the individual events are \"quantized\" into the times of the *frames*. When writing this data back to an XIO file, the events will have these new timestamps instead of their original ones."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "list(quantize(f.xio_quicklinegen(5000, 5300), 'VeniceHubReplay/Venice/Body1'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "[{'JointPositions1': <mumodo.InstantIO.MFVec3f at 0x112fd5cd0>,\n",
        "  'JointPositions2': <mumodo.InstantIO.MFVec3f at 0x10fecebd0>,\n",
        "  'JointPositions3': <mumodo.InstantIO.MFVec3f at 0x112fd5e90>,\n",
        "  'JointPositions4': <mumodo.InstantIO.MFVec3f at 0x112fd5a50>,\n",
        "  'JointPositions5': <mumodo.InstantIO.MFVec3f at 0x10f6299d0>,\n",
        "  'JointPositions6': <mumodo.InstantIO.MFVec3f at 0x10f629950>,\n",
        "  'time': 1429192629594},\n",
        " {'JointPositions1': <mumodo.InstantIO.MFVec3f at 0x10fece710>,\n",
        "  'JointPositions2': <mumodo.InstantIO.MFVec3f at 0x10fecea10>,\n",
        "  'JointPositions3': <mumodo.InstantIO.MFVec3f at 0x112fd5d50>,\n",
        "  'JointPositions4': <mumodo.InstantIO.MFVec3f at 0x10fece550>,\n",
        "  'JointPositions5': <mumodo.InstantIO.MFVec3f at 0x10fece790>,\n",
        "  'JointPositions6': <mumodo.InstantIO.MFVec3f at 0x10fece650>,\n",
        "  'time': 1429192629629},\n",
        " {'JointPositions1': <mumodo.InstantIO.MFVec3f at 0x11098a990>,\n",
        "  'JointPositions2': <mumodo.InstantIO.MFVec3f at 0x11098a6d0>,\n",
        "  'JointPositions3': <mumodo.InstantIO.MFVec3f at 0x112fd5f10>,\n",
        "  'JointPositions4': <mumodo.InstantIO.MFVec3f at 0x10feceb90>,\n",
        "  'JointPositions5': <mumodo.InstantIO.MFVec3f at 0x11098a8d0>,\n",
        "  'JointPositions6': <mumodo.InstantIO.MFVec3f at 0x11098a710>,\n",
        "  'time': 1429192629661},\n",
        " {'JointPositions1': <mumodo.InstantIO.MFVec3f at 0x102f3ebd0>,\n",
        "  'JointPositions2': <mumodo.InstantIO.MFVec3f at 0x102f3e490>,\n",
        "  'JointPositions3': <mumodo.InstantIO.MFVec3f at 0x10fece1d0>,\n",
        "  'JointPositions4': <mumodo.InstantIO.MFVec3f at 0x102f3ec10>,\n",
        "  'JointPositions5': <mumodo.InstantIO.MFVec3f at 0x102f3e510>,\n",
        "  'JointPositions6': <mumodo.InstantIO.MFVec3f at 0x102f3eb90>,\n",
        "  'time': 1429192629694},\n",
        " {'JointPositions1': <mumodo.InstantIO.MFVec3f at 0x112fd5f90>,\n",
        "  'JointPositions2': <mumodo.InstantIO.MFVec3f at 0x112fd5b10>,\n",
        "  'JointPositions3': <mumodo.InstantIO.MFVec3f at 0x102f3f350>,\n",
        "  'JointPositions4': <mumodo.InstantIO.MFVec3f at 0x112fd5ed0>,\n",
        "  'JointPositions5': <mumodo.InstantIO.MFVec3f at 0x112fd5d90>,\n",
        "  'JointPositions6': <mumodo.InstantIO.MFVec3f at 0x112fd5c10>,\n",
        "  'time': 1429192629728},\n",
        " {'JointPositions1': <mumodo.InstantIO.MFVec3f at 0x10fece810>,\n",
        "  'JointPositions2': <mumodo.InstantIO.MFVec3f at 0x10fece2d0>,\n",
        "  'JointPositions3': <mumodo.InstantIO.MFVec3f at 0x112fd5c50>,\n",
        "  'JointPositions4': <mumodo.InstantIO.MFVec3f at 0x102f3e4d0>,\n",
        "  'JointPositions5': <mumodo.InstantIO.MFVec3f at 0x10fece910>,\n",
        "  'JointPositions6': <mumodo.InstantIO.MFVec3f at 0x10fece250>,\n",
        "  'time': 1429192629761},\n",
        " {'JointPositions1': <mumodo.InstantIO.MFVec3f at 0x10f6128d0>,\n",
        "  'JointPositions2': <mumodo.InstantIO.MFVec3f at 0x10f612150>,\n",
        "  'JointPositions3': <mumodo.InstantIO.MFVec3f at 0x102f3f310>,\n",
        "  'JointPositions4': <mumodo.InstantIO.MFVec3f at 0x10f612f90>,\n",
        "  'JointPositions5': <mumodo.InstantIO.MFVec3f at 0x10f612890>,\n",
        "  'JointPositions6': <mumodo.InstantIO.MFVec3f at 0x10f612090>,\n",
        "  'time': 1429192629794},\n",
        " {'JointPositions1': <mumodo.InstantIO.MFVec3f at 0x10f609dd0>,\n",
        "  'JointPositions2': <mumodo.InstantIO.MFVec3f at 0x102f3ec50>,\n",
        "  'JointPositions3': <mumodo.InstantIO.MFVec3f at 0x10f609d50>,\n",
        "  'JointPositions4': <mumodo.InstantIO.MFVec3f at 0x10f609650>,\n",
        "  'JointPositions5': <mumodo.InstantIO.MFVec3f at 0x10f609d90>,\n",
        "  'JointPositions6': <mumodo.InstantIO.MFVec3f at 0x10f609d10>,\n",
        "  'time': 1429192629828},\n",
        " {'JointPositions1': <mumodo.InstantIO.MFVec3f at 0x112fd5fd0>,\n",
        "  'JointPositions2': <mumodo.InstantIO.MFVec3f at 0x112fd5dd0>,\n",
        "  'JointPositions3': <mumodo.InstantIO.MFVec3f at 0x112fd5f50>,\n",
        "  'JointPositions4': <mumodo.InstantIO.MFVec3f at 0x112fd5d10>,\n",
        "  'JointPositions5': <mumodo.InstantIO.MFVec3f at 0x112fd5e50>,\n",
        "  'JointPositions6': <mumodo.InstantIO.MFVec3f at 0x112fd5c90>,\n",
        "  'time': 1429192629860}]"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Inc_Reco files"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "inc_recos are special files that are useful within the Incremental Unit (IU) framework.\n",
      "\n",
      "They store information about units at different update times. Automatic Speech Recognition (ASR) results that are output incrementally can be stored in these files. Each update time is accompanied by a \"chunk\" of the output (the output at that time).\n",
      "\n",
      "Here is what they look like:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('sampledata/test.inc_reco') as f:\n",
      "    lines = 0\n",
      "    while lines < 22:\n",
      "        print f.readline()[:-1]\n",
      "        lines += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time: 2.00\n",
        "1.888250\t2.044875\toh\n",
        "\n",
        "Time: 2.20\n",
        "1.888250\t2.044875\toh\n",
        "2.044875\t2.111625\ti\n",
        "2.111625\t2.194750\tdon't\n",
        "\n",
        "Time: 2.80\n",
        "1.888250\t2.044875\toh\n",
        "2.044875\t2.111625\ti\n",
        "2.111625\t2.194750\tdon't\n",
        "2.479500\t2.537625\ti\n",
        "2.537625\t2.657625\tdon't\n",
        "2.657625\t2.747625\tknow\n",
        "2.747625\t2.837625\ti\n",
        "\n",
        "Time: 2.95\n",
        "1.888250\t2.044875\toh\n",
        "2.044875\t2.111625\ti\n",
        "2.111625\t2.194750\tdon't\n",
        "2.479500\t2.537625\ti\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "But the IncReco class handles these files nicely, e.g."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myincreco = IncReco(\"sampledata/test.inc_reco\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get all the update times\n",
      "print myincreco.get_times()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[2.0, 2.2, 2.8, 2.95, 3.15, 3.45, 3.7, 4.11, 4.42, 4.59, 5.44]\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get the latest chunk at a specific time\n",
      "myincreco.get_latest_chunk(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "{'Chunk': [['1.888250', '2.044875', 'oh'],\n",
        "  ['2.044875', '2.111625', 'i'],\n",
        "  ['2.111625', '2.194750', \"don't\"],\n",
        "  ['2.479500', '2.537625', 'i'],\n",
        "  ['2.537625', '2.657625', \"don't\"],\n",
        "  ['2.657625', '2.747625', 'know'],\n",
        "  ['2.747625', '2.837625', 'i'],\n",
        "  ['2.837625', '2.927625', 'had'],\n",
        "  ['2.927625', '2.957625', 'a'],\n",
        "  ['2.957625', '3.107625', 'little'],\n",
        "  ['3.107625', '3.197625', 'bit'],\n",
        "  ['3.197625', '3.307625', 'more'],\n",
        "  ['3.307625', '3.507625', 'time'],\n",
        "  ['3.507625', '3.577625', 'to'],\n",
        "  ['3.577625', '3.827625', 'think'],\n",
        "  ['3.827625', '3.987625', 'about'],\n",
        "  ['3.987625', '4.047625', 'it'],\n",
        "  ['4.047625', '4.077625', 'i'],\n",
        "  ['4.077625', '4.197625', 'was'],\n",
        "  ['4.197625', '4.517625', 'thinking'],\n",
        "  ['4.517625', '4.727625', 'of'],\n",
        "  ['4.727625', '5.037625', 'like']],\n",
        " 'Time': 4.59}"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get the very last chunk -> final output\n",
      "myincreco.get_last_chunk()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "{'Chunk': [['1.888250', '2.044875', 'oh'],\n",
        "  ['2.044875', '2.111625', 'i'],\n",
        "  ['2.111625', '2.194750', \"don't\"],\n",
        "  ['2.479500', '2.537625', 'i'],\n",
        "  ['2.537625', '2.657625', \"don't\"],\n",
        "  ['2.657625', '2.747625', 'know'],\n",
        "  ['2.747625', '2.837625', 'i'],\n",
        "  ['2.837625', '2.927625', 'had'],\n",
        "  ['2.927625', '2.957625', 'a'],\n",
        "  ['2.957625', '3.107625', 'little'],\n",
        "  ['3.107625', '3.197625', 'bit'],\n",
        "  ['3.197625', '3.307625', 'more'],\n",
        "  ['3.307625', '3.507625', 'time'],\n",
        "  ['3.507625', '3.577625', 'to'],\n",
        "  ['3.577625', '3.827625', 'think'],\n",
        "  ['3.827625', '3.987625', 'about'],\n",
        "  ['3.987625', '4.047625', 'it'],\n",
        "  ['4.047625', '4.077625', 'i'],\n",
        "  ['4.077625', '4.197625', 'was'],\n",
        "  ['4.197625', '4.517625', 'thinking'],\n",
        "  ['4.517625', '4.727625', 'of'],\n",
        "  ['4.727625', '5.037625', 'like'],\n",
        "  ['5.037625', '5.324375', 'uh']],\n",
        " 'Time': 5.44}"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In addition, you can import an IncReco such as the above as a dictionary of IntervalFrames (one for each chunk):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myrecodict = open_intervalframe_from_increco('sampledata/test.inc_reco')\n",
      "print myrecodict.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['4.11', '3.45', '5.44', '2.95', '3.15', '4.42', '3.7', '2.8', '4.59', '2.2', '2.0']\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#display the final output intervalframe\n",
      "myrecodict['5.44']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>start_time</th>\n",
        "      <th>end_time</th>\n",
        "      <th>text</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td> 1.888250</td>\n",
        "      <td> 2.044875</td>\n",
        "      <td>       oh</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td> 2.044875</td>\n",
        "      <td> 2.111625</td>\n",
        "      <td>        i</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td> 2.111625</td>\n",
        "      <td> 2.194750</td>\n",
        "      <td>    don't</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td> 2.479500</td>\n",
        "      <td> 2.537625</td>\n",
        "      <td>        i</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td> 2.537625</td>\n",
        "      <td> 2.657625</td>\n",
        "      <td>    don't</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td> 2.657625</td>\n",
        "      <td> 2.747625</td>\n",
        "      <td>     know</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td> 2.747625</td>\n",
        "      <td> 2.837625</td>\n",
        "      <td>        i</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td> 2.837625</td>\n",
        "      <td> 2.927625</td>\n",
        "      <td>      had</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td> 2.927625</td>\n",
        "      <td> 2.957625</td>\n",
        "      <td>        a</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td> 2.957625</td>\n",
        "      <td> 3.107625</td>\n",
        "      <td>   little</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td> 3.107625</td>\n",
        "      <td> 3.197625</td>\n",
        "      <td>      bit</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td> 3.197625</td>\n",
        "      <td> 3.307625</td>\n",
        "      <td>     more</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td> 3.307625</td>\n",
        "      <td> 3.507625</td>\n",
        "      <td>     time</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td> 3.507625</td>\n",
        "      <td> 3.577625</td>\n",
        "      <td>       to</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td> 3.577625</td>\n",
        "      <td> 3.827625</td>\n",
        "      <td>    think</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15</th>\n",
        "      <td> 3.827625</td>\n",
        "      <td> 3.987625</td>\n",
        "      <td>    about</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td> 3.987625</td>\n",
        "      <td> 4.047625</td>\n",
        "      <td>       it</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17</th>\n",
        "      <td> 4.047625</td>\n",
        "      <td> 4.077625</td>\n",
        "      <td>        i</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18</th>\n",
        "      <td> 4.077625</td>\n",
        "      <td> 4.197625</td>\n",
        "      <td>      was</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19</th>\n",
        "      <td> 4.197625</td>\n",
        "      <td> 4.517625</td>\n",
        "      <td> thinking</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20</th>\n",
        "      <td> 4.517625</td>\n",
        "      <td> 4.727625</td>\n",
        "      <td>       of</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>21</th>\n",
        "      <td> 4.727625</td>\n",
        "      <td> 5.037625</td>\n",
        "      <td>     like</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>22</th>\n",
        "      <td> 5.037625</td>\n",
        "      <td> 5.324375</td>\n",
        "      <td>       uh</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "    start_time  end_time      text\n",
        "0     1.888250  2.044875        oh\n",
        "1     2.044875  2.111625         i\n",
        "2     2.111625  2.194750     don't\n",
        "3     2.479500  2.537625         i\n",
        "4     2.537625  2.657625     don't\n",
        "5     2.657625  2.747625      know\n",
        "6     2.747625  2.837625         i\n",
        "7     2.837625  2.927625       had\n",
        "8     2.927625  2.957625         a\n",
        "9     2.957625  3.107625    little\n",
        "10    3.107625  3.197625       bit\n",
        "11    3.197625  3.307625      more\n",
        "12    3.307625  3.507625      time\n",
        "13    3.507625  3.577625        to\n",
        "14    3.577625  3.827625     think\n",
        "15    3.827625  3.987625     about\n",
        "16    3.987625  4.047625        it\n",
        "17    4.047625  4.077625         i\n",
        "18    4.077625  4.197625       was\n",
        "19    4.197625  4.517625  thinking\n",
        "20    4.517625  4.727625        of\n",
        "21    4.727625  5.037625      like\n",
        "22    5.037625  5.324375        uh"
       ]
      }
     ],
     "prompt_number": 29
    }
   ],
   "metadata": {}
  }
 ]
}